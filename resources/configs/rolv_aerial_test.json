{
  "device": "cuda:4",
  "seed": 123,
  "env_id": "RocketLeague-v0",
  "custom_envs": [
    "rlgym_distrib_rl_wrapper"
  ],
  "agent": {"type" : "pg"},
  "log_to_wandb": true,
  "wandb": {
    "project": "idle_time",
    "group": "reward_experiments",
    "name": "Aerial Reward Test 8"
  },

  "value_estimator":
  {
    "type" : ["ff", "continuous"],
    "init_type": "normc",
    "init_std" : 1.4,
    "action_init_std": 1.0,
    "action_noise_std" : 0.0,
    "observation_clip_range" : null,
    "normalize_observations" : false,
    "action_parser" : "linear",

    "layers" :
    {
      "ff1":
      {
        "type" : "ff",
        "num_nodes" : 512,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff2":
      {
        "type" : "ff",
        "num_nodes" : 512,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff3":
      {
        "type" : "ff",
        "num_nodes" : 512,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff4":
      {
        "type" : "ff",
        "num_nodes" : 512,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff5":
      {
        "type" : "ff",
        "num_nodes" : 512,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff6":
      {
        "type" : "ff",
        "num_nodes" : 512,
        "activation_function" : "selu",
        "extra" : null
      },
      "output" :
      {
        "type": "output",
        "activation_function" : "linear",
        "extra" : null
      }
    }
  },
  "policy":
  {
    "type" : ["ff", "discrete"],
    "init_type": "normc",
    "init_std": 1.0,
    "action_init_std": 1.0,
    "observation_clip_range": null,
    "normalize_observations": false,
    "layers":
    {
      "ff1":
      {
        "type" : "ff",
        "num_nodes" : 256,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff2":
      {
        "type" : "ff",
        "num_nodes" : 256,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff3":
      {
        "type" : "ff",
        "num_nodes" : 256,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff4":
      {
        "type" : "ff",
        "num_nodes" : 256,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff5":
      {
        "type" : "ff",
        "num_nodes" : 256,
        "activation_function" : "selu",
        "extra" : null
      },
      "ff6":
      {
        "type" : "ff",
        "num_nodes" : 256,
        "activation_function" : "selu",
        "extra" : null
      },
      "output":
      {
          "type": "out",
          "extra": [3,3,3,3,3,2,2,2],
          "num_nodes": 21,
          "activation_function": "softmax"
      }
    }
  },

  "policy_gradient_optimizer":
  {
    "type": "torch adam",
    "lr": 1e-4
  },

  // not used at the moment
  "novelty_gradient_optimizer":
  {
    "type": "dsgd",
    "step_size": 3e-4
  },

  "value_gradient_optimizer":
  {
    "type": "torch adam",
    "lr": 1e-4
  },

  "policy_optimizer":
  {
    "type": "pg",
    "gamma": 0.995,
    "max_kl": 1.0,
    "batch_size": 100000, // no minibatches, so must fit in VRAM
    "clip_range": 0.2,
    "gae_lambda": 0.95, // should be slightly smaller than gamma
    "entropy_coef": 0.005,
    "max_timesteps": 1e16,
    "eps_per_eval": 50,
    /**
     * Percentage of returns that needs to be "fresh" prior to an update
     * occurring
     */
    "new_returns_proportion": 1
    // "timesteps_per_update": 100000
  },

  "adaptive_omega":
  {
    "mean_threshold": 1.035,
    "reward_history_size": 40,
    "min_value": 0.0,
    "max_value": 1,
    "default": 0.0
  },

  "experience_replay":
  {
    "max_buffer_size": 800000
  },

  "strategy":
  {
    "max_history_size": 200,
    "num_frames": 200,
    "steps_per_eval" : 1,
    "num_fd_perturbations" : 250,
    "fd_noise_std" : 0.1
  },

  "env_kwargs": {
    "tick_skip": 8,
    "team_size": 1,
    "game_speed": 100,
    "spawn_opponents": false,
    "action_parser": "necto",
    "obs_builder": "advanced",
    "boost_consumption": 0,
    "state_setter": {
      "weighted_sample": {
        "state_setters": [
          "default",
          "random"
        ],
        "weights": [
          0.5,
          0.5
        ]
      }
    },
    "reward_function": {
      "combined": {
        "rewards": [
          "velocity_player_to_ball",
          {
            "rolv_aerial": {
              "tick_skip": 8,
              "scale_by_upness": true
            }
          }
        ],
        "weights": [
          1.0,
          1000.0
        ]
      }
    },
    "terminal_conditions": {
      "timeout": {
        "max_steps": 4500 // 5 minutes @ 15 steps/sec
      },
      "no_touch_timeout": {
        "max_steps": 450 // 5 minutes @ 15 steps/sec
      },
      "goal_scored": {},
      "aerial_task": {}
    }
  },

  /*"lr_adjuster":
  {
    "clip_target": 0.1,
    "rate": 1.1,
    "max_lr": 1,
    "min_lr": 1e-7
  }*/
}
